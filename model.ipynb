{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import glob, os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "videos = glob.glob(\"videos\"+\"/*.mp4\")\n",
    "#config_path = deeplabcut.create_new_project('open_field_zone', 'Me', videos, \"./open_field_model/\", copy_videos=True, multianimal=False)\n",
    "#config_path = glob.glob(\"open_field_model\\*\\*.yaml\")[0]\n",
    "config_path = r\"C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\config.yaml\"\n",
    "print(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.12  seconds.\n",
      "Extracting and downsampling... 31088  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31088it [00:40, 765.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.0  seconds.\n",
      "Extracting and downsampling... 31086  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31086it [00:43, 708.64it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31109  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31109it [00:44, 701.68it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31091  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31091it [00:44, 697.91it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31073  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31073it [00:44, 705.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.17  seconds.\n",
      "Extracting and downsampling... 31089  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31089it [00:41, 755.15it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.17  seconds.\n",
      "Extracting and downsampling... 31089  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31089it [00:42, 730.53it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.65  seconds.\n",
      "Extracting and downsampling... 31116  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31116it [00:41, 753.29it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.46  seconds.\n",
      "Extracting and downsampling... 31094  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31094it [00:41, 746.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.94  seconds.\n",
      "Extracting and downsampling... 31085  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31085it [01:03, 486.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.46  seconds.\n",
      "Extracting and downsampling... 31094  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31094it [01:00, 513.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.88  seconds.\n",
      "Extracting and downsampling... 31102  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31102it [01:07, 463.04it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.88  seconds.\n",
      "Extracting and downsampling... 31084  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31084it [01:08, 454.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.71  seconds.\n",
      "Extracting and downsampling... 31099  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31099it [01:03, 487.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.54  seconds.\n",
      "Extracting and downsampling... 31114  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31114it [01:02, 501.04it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.54  seconds.\n",
      "Extracting and downsampling... 31096  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31096it [01:03, 486.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.59  seconds.\n",
      "Extracting and downsampling... 31097  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31097it [01:07, 462.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.41  seconds.\n",
      "Extracting and downsampling... 31093  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31093it [01:02, 497.84it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.41  seconds.\n",
      "Extracting and downsampling... 31075  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31075it [00:58, 528.27it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31109  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31109it [00:55, 555.60it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.35  seconds.\n",
      "Extracting and downsampling... 31092  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31092it [01:00, 518.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.0  seconds.\n",
      "Extracting and downsampling... 31086  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31086it [00:56, 549.08it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.65  seconds.\n",
      "Extracting and downsampling... 31062  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31062it [00:55, 562.34it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.12  seconds.\n",
      "Extracting and downsampling... 31088  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31088it [00:59, 525.82it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.23  seconds.\n",
      "Extracting and downsampling... 31126  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31126it [00:58, 534.83it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31073  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31073it [00:58, 533.48it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.48  seconds.\n",
      "Extracting and downsampling... 31077  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31077it [00:57, 540.80it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.0  seconds.\n",
      "Extracting and downsampling... 31104  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31104it [00:59, 519.77it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31073  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31073it [00:57, 541.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.17  seconds.\n",
      "Extracting and downsampling... 31089  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31089it [00:56, 547.09it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.23  seconds.\n",
      "Extracting and downsampling... 31090  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31090it [00:56, 545.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.12  seconds.\n",
      "Extracting and downsampling... 31106  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31106it [00:59, 523.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.88  seconds.\n",
      "Extracting and downsampling... 31102  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31102it [00:57, 537.77it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31091  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31091it [00:57, 537.83it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.77  seconds.\n",
      "Extracting and downsampling... 31100  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31100it [01:04, 483.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.06  seconds.\n",
      "Extracting and downsampling... 31087  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31087it [00:45, 678.10it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.71  seconds.\n",
      "Extracting and downsampling... 31081  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31081it [01:00, 515.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.23  seconds.\n",
      "Extracting and downsampling... 31072  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31072it [00:55, 564.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.59  seconds.\n",
      "Extracting and downsampling... 31079  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31079it [00:57, 535.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.52  seconds.\n",
      "Extracting and downsampling... 31095  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31095it [00:58, 530.54it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.29  seconds.\n",
      "Extracting and downsampling... 31091  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31091it [01:00, 517.22it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.17  seconds.\n",
      "Extracting and downsampling... 31089  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31089it [00:56, 546.84it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.52  seconds.\n",
      "Extracting and downsampling... 31095  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31095it [00:58, 527.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.41  seconds.\n",
      "Extracting and downsampling... 31075  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31075it [00:56, 550.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.41  seconds.\n",
      "Extracting and downsampling... 31093  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31093it [00:37, 818.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.12  seconds.\n",
      "Extracting and downsampling... 31088  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31088it [00:38, 808.73it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1800.52  seconds.\n",
      "Extracting and downsampling... 31095  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31095it [00:37, 829.00it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1799.77  seconds.\n",
      "Extracting and downsampling... 31082  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31082it [00:36, 851.10it/s]\n",
      "c:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 10\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 11\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 12\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 13\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 14\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 15\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 16\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 17\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 18\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 19\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 20\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 21\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 22\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 23\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 24\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 25\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 26\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 27\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 28\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 29\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 30\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 31\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 32\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 33\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 34\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 35\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 36\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 37\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 38\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 39\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 40\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 41\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 42\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 43\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 44\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 45\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 46\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 47\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 48\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 6\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 7\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 8\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\labeled-data\\Test 9\\CollectedData_Me.h5  not found (perhaps not annotated).\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  2,\n",
       "  (array([ 48,  94,  95,   8,  97,  22,   7,  10,  45,  89,  33,  50,   2,\n",
       "           60, 119,  74,  30,  43, 111,  76,  63,  59,  16,  24, 110,  13,\n",
       "           54,  93,  26,  68,  51, 113, 107,  61,   3,  96,   6,  75, 100,\n",
       "           91, 104,  84,  90,  66,  27,  18,  99,  11,  62,  71,  56,  98,\n",
       "           86,   1,  73,  42,  41,   4,  15,  17,  52,  40,  38,   5,  53,\n",
       "          109, 114,   0,  34,  28,  55,  35,  23,  31,  78,  57,  92, 102,\n",
       "           32, 101,  14,  85,  19,  29,  49,  82, 116, 118,  79,  69,  80,\n",
       "           20, 112,  72,  77,  25,  37,  81, 105,  46, 108,  39,  65,  58,\n",
       "           12, 106,  88,  70,  87,  36,  21,  83,   9, 103]),\n",
       "   array([115,  67,  64, 117,  47,  44])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with configuration:\n",
      "data:\n",
      "  colormode: RGB\n",
      "  inference:\n",
      "    normalize_images: True\n",
      "    auto_padding:\n",
      "      pad_width_divisor: 32\n",
      "      pad_height_divisor: 32\n",
      "  train:\n",
      "    affine:\n",
      "      p: 0.5\n",
      "      rotation: 30\n",
      "      scaling: [1.0, 1.0]\n",
      "      translation: 0\n",
      "    collate:\n",
      "      type: ResizeFromDataSizeCollate\n",
      "      min_scale: 0.4\n",
      "      max_scale: 1.0\n",
      "      min_short_side: 128\n",
      "      max_short_side: 1152\n",
      "      multiple_of: 32\n",
      "      to_square: False\n",
      "    covering: False\n",
      "    gaussian_noise: 12.75\n",
      "    hist_eq: False\n",
      "    motion_blur: False\n",
      "    normalize_images: True\n",
      "device: auto\n",
      "metadata:\n",
      "  project_path: C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\n",
      "  pose_config_path: C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\dlc-models-pytorch\\iteration-0\\open_field_zoneJul11-trainset95shuffle1\\train\\pose_cfg.yaml\n",
      "  bodyparts: ['Tete', 'Corps', 'Queue']\n",
      "  unique_bodyparts: []\n",
      "  individuals: ['animal']\n",
      "  with_identity: None\n",
      "method: bu\n",
      "model:\n",
      "  backbone:\n",
      "    type: HRNet\n",
      "    model_name: hrnet_w48\n",
      "    freeze_bn_stats: True\n",
      "    freeze_bn_weights: False\n",
      "    interpolate_branches: False\n",
      "    increased_channel_count: False\n",
      "  backbone_output_channels: 48\n",
      "  heads:\n",
      "    bodypart:\n",
      "      type: HeatmapHead\n",
      "      weight_init: normal\n",
      "      predictor:\n",
      "        type: HeatmapPredictor\n",
      "        apply_sigmoid: False\n",
      "        clip_scores: True\n",
      "        location_refinement: True\n",
      "        locref_std: 7.2801\n",
      "      target_generator:\n",
      "        type: HeatmapGaussianGenerator\n",
      "        num_heatmaps: 3\n",
      "        pos_dist_thresh: 17\n",
      "        heatmap_mode: KEYPOINT\n",
      "        generate_locref: True\n",
      "        locref_std: 7.2801\n",
      "      criterion:\n",
      "        heatmap:\n",
      "          type: WeightedMSECriterion\n",
      "          weight: 1.0\n",
      "        locref:\n",
      "          type: WeightedHuberCriterion\n",
      "          weight: 0.05\n",
      "      heatmap_config:\n",
      "        channels: [48, 3]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "      locref_config:\n",
      "        channels: [48, 6]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "net_type: hrnet_w48\n",
      "runner:\n",
      "  type: PoseTrainingRunner\n",
      "  gpus: None\n",
      "  key_metric: test.mAP\n",
      "  key_metric_asc: True\n",
      "  eval_interval: 1\n",
      "  optimizer:\n",
      "    type: AdamW\n",
      "    params:\n",
      "      lr: 0.0001\n",
      "  scheduler:\n",
      "    type: LRListScheduler\n",
      "    params:\n",
      "      lr_list: [[1e-05], [1e-06]]\n",
      "      milestones: [160, 190]\n",
      "  snapshots:\n",
      "    max_snapshots: 5\n",
      "    save_epochs: 25\n",
      "    save_optimizer_state: False\n",
      "train_settings:\n",
      "  batch_size: 1\n",
      "  dataloader_workers: 0\n",
      "  dataloader_pin_memory: True\n",
      "  display_iters: 500\n",
      "  epochs: 200\n",
      "  seed: 42\n",
      "Loading pretrained weights from Hugging Face hub (timm/hrnet_w48.ms_in1k)\n",
      "[timm/hrnet_w48.ms_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.weight, incre_modules.0.0.conv1.weight, incre_modules.0.0.conv2.weight, incre_modules.0.0.conv3.weight, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.weight, incre_modules.1.0.conv1.weight, incre_modules.1.0.conv2.weight, incre_modules.1.0.conv3.weight, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.weight, incre_modules.2.0.conv1.weight, incre_modules.2.0.conv2.weight, incre_modules.2.0.conv3.weight, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.weight, incre_modules.3.0.conv1.weight, incre_modules.3.0.conv2.weight, incre_modules.3.0.conv3.weight, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.num_batches_tracked, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Data Transforms:\n",
      "  Training:   Compose([\n",
      "  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),\n",
      "  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "  Validation: Compose([\n",
      "  PadIfNeeded(always_apply=False, p=1.0, min_height=None, min_width=None, pad_height_divisor=32, pad_width_divisor=32, position=PositionType.RANDOM, border_mode=4, value=None, mask_value=None),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}\n",
      "\n",
      "Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.\n",
      "This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.\n",
      "If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. \n",
      "This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).\n",
      "\n",
      "Using 114 images and 6 for testing\n",
      "\n",
      "Starting pose model training...\n",
      "--------------------------------------------------\n",
      "Training for epoch 1 done, starting evaluation\n",
      "Epoch 1 performance:\n",
      "metrics/test.rmse:  24.528\n",
      "metrics/test.rmse_pcutoff:18.649\n",
      "metrics/test.mAP:   0.561\n",
      "metrics/test.mAR:   1.667\n",
      "metrics/test.mAP_pcutoff:0.000\n",
      "metrics/test.mAR_pcutoff:0.000\n",
      "Epoch 1/200 (lr=0.0001), train loss 0.00998, valid loss 0.00654\n",
      "Training for epoch 2 done, starting evaluation\n",
      "Epoch 2 performance:\n",
      "metrics/test.rmse:  8.589\n",
      "metrics/test.rmse_pcutoff:4.370\n",
      "metrics/test.mAP:   22.525\n",
      "metrics/test.mAR:   30.000\n",
      "metrics/test.mAP_pcutoff:12.970\n",
      "metrics/test.mAR_pcutoff:16.667\n",
      "Epoch 2/200 (lr=0.0001), train loss 0.00512, valid loss 0.00539\n",
      "Training for epoch 3 done, starting evaluation\n",
      "Epoch 3 performance:\n",
      "metrics/test.rmse:  7.536\n",
      "metrics/test.rmse_pcutoff:8.001\n",
      "metrics/test.mAP:   44.530\n",
      "metrics/test.mAR:   45.000\n",
      "metrics/test.mAP_pcutoff:21.871\n",
      "metrics/test.mAR_pcutoff:25.000\n",
      "Epoch 3/200 (lr=0.0001), train loss 0.00398, valid loss 0.00334\n",
      "Training for epoch 4 done, starting evaluation\n",
      "Epoch 4 performance:\n",
      "metrics/test.rmse:  28.258\n",
      "metrics/test.rmse_pcutoff:28.258\n",
      "metrics/test.mAP:   28.936\n",
      "metrics/test.mAR:   38.333\n",
      "metrics/test.mAP_pcutoff:28.936\n",
      "metrics/test.mAR_pcutoff:38.333\n",
      "Epoch 4/200 (lr=0.0001), train loss 0.00365, valid loss 0.00327\n",
      "Training for epoch 5 done, starting evaluation\n",
      "Epoch 5 performance:\n",
      "metrics/test.rmse:  3.782\n",
      "metrics/test.rmse_pcutoff:3.782\n",
      "metrics/test.mAP:   52.713\n",
      "metrics/test.mAR:   53.333\n",
      "metrics/test.mAP_pcutoff:52.713\n",
      "metrics/test.mAR_pcutoff:53.333\n",
      "Epoch 5/200 (lr=0.0001), train loss 0.00258, valid loss 0.00291\n",
      "Training for epoch 6 done, starting evaluation\n",
      "Epoch 6 performance:\n",
      "metrics/test.rmse:  3.386\n",
      "metrics/test.rmse_pcutoff:3.386\n",
      "metrics/test.mAP:   60.619\n",
      "metrics/test.mAR:   63.333\n",
      "metrics/test.mAP_pcutoff:60.619\n",
      "metrics/test.mAR_pcutoff:63.333\n",
      "Epoch 6/200 (lr=0.0001), train loss 0.00217, valid loss 0.00242\n",
      "Training for epoch 7 done, starting evaluation\n",
      "Epoch 7 performance:\n",
      "metrics/test.rmse:  3.571\n",
      "metrics/test.rmse_pcutoff:3.412\n",
      "metrics/test.mAP:   60.743\n",
      "metrics/test.mAR:   61.667\n",
      "metrics/test.mAP_pcutoff:24.172\n",
      "metrics/test.mAR_pcutoff:25.000\n",
      "Epoch 7/200 (lr=0.0001), train loss 0.00221, valid loss 0.00227\n",
      "Training for epoch 8 done, starting evaluation\n",
      "Epoch 8 performance:\n",
      "metrics/test.rmse:  2.883\n",
      "metrics/test.rmse_pcutoff:2.883\n",
      "metrics/test.mAP:   63.267\n",
      "metrics/test.mAR:   65.000\n",
      "metrics/test.mAP_pcutoff:63.267\n",
      "metrics/test.mAR_pcutoff:65.000\n",
      "Epoch 8/200 (lr=0.0001), train loss 0.00190, valid loss 0.00167\n",
      "Training for epoch 9 done, starting evaluation\n",
      "Epoch 9 performance:\n",
      "metrics/test.rmse:  3.253\n",
      "metrics/test.rmse_pcutoff:3.253\n",
      "metrics/test.mAP:   59.446\n",
      "metrics/test.mAR:   61.667\n",
      "metrics/test.mAP_pcutoff:59.446\n",
      "metrics/test.mAR_pcutoff:61.667\n",
      "Epoch 9/200 (lr=0.0001), train loss 0.00161, valid loss 0.00184\n",
      "Training for epoch 10 done, starting evaluation\n",
      "Epoch 10 performance:\n",
      "metrics/test.rmse:  2.262\n",
      "metrics/test.rmse_pcutoff:2.262\n",
      "metrics/test.mAP:   76.733\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:76.733\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 10/200 (lr=0.0001), train loss 0.00170, valid loss 0.00138\n",
      "Training for epoch 11 done, starting evaluation\n",
      "Epoch 11 performance:\n",
      "metrics/test.rmse:  2.458\n",
      "metrics/test.rmse_pcutoff:2.458\n",
      "metrics/test.mAP:   74.307\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:74.307\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 11/200 (lr=0.0001), train loss 0.00156, valid loss 0.00188\n",
      "Training for epoch 12 done, starting evaluation\n",
      "Epoch 12 performance:\n",
      "metrics/test.rmse:  3.341\n",
      "metrics/test.rmse_pcutoff:3.271\n",
      "metrics/test.mAP:   57.574\n",
      "metrics/test.mAR:   60.000\n",
      "metrics/test.mAP_pcutoff:57.574\n",
      "metrics/test.mAR_pcutoff:60.000\n",
      "Epoch 12/200 (lr=0.0001), train loss 0.00157, valid loss 0.00185\n",
      "Training for epoch 13 done, starting evaluation\n",
      "Epoch 13 performance:\n",
      "metrics/test.rmse:  3.706\n",
      "metrics/test.rmse_pcutoff:3.706\n",
      "metrics/test.mAP:   47.054\n",
      "metrics/test.mAR:   50.000\n",
      "metrics/test.mAP_pcutoff:47.054\n",
      "metrics/test.mAR_pcutoff:50.000\n",
      "Epoch 13/200 (lr=0.0001), train loss 0.00135, valid loss 0.00212\n",
      "Training for epoch 14 done, starting evaluation\n",
      "Epoch 14 performance:\n",
      "metrics/test.rmse:  2.700\n",
      "metrics/test.rmse_pcutoff:2.700\n",
      "metrics/test.mAP:   71.361\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:71.361\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 14/200 (lr=0.0001), train loss 0.00134, valid loss 0.00156\n",
      "Training for epoch 15 done, starting evaluation\n",
      "Epoch 15 performance:\n",
      "metrics/test.rmse:  3.306\n",
      "metrics/test.rmse_pcutoff:3.398\n",
      "metrics/test.mAP:   56.832\n",
      "metrics/test.mAR:   60.000\n",
      "metrics/test.mAP_pcutoff:56.832\n",
      "metrics/test.mAR_pcutoff:60.000\n",
      "Epoch 15/200 (lr=0.0001), train loss 0.00141, valid loss 0.00198\n",
      "Training for epoch 16 done, starting evaluation\n",
      "Epoch 16 performance:\n",
      "metrics/test.rmse:  3.117\n",
      "metrics/test.rmse_pcutoff:2.886\n",
      "metrics/test.mAP:   53.886\n",
      "metrics/test.mAR:   60.000\n",
      "metrics/test.mAP_pcutoff:29.545\n",
      "metrics/test.mAR_pcutoff:31.667\n",
      "Epoch 16/200 (lr=0.0001), train loss 0.00198, valid loss 0.00250\n",
      "Training for epoch 17 done, starting evaluation\n",
      "Epoch 17 performance:\n",
      "metrics/test.rmse:  3.976\n",
      "metrics/test.rmse_pcutoff:3.976\n",
      "metrics/test.mAP:   54.832\n",
      "metrics/test.mAR:   55.000\n",
      "metrics/test.mAP_pcutoff:54.832\n",
      "metrics/test.mAR_pcutoff:55.000\n",
      "Epoch 17/200 (lr=0.0001), train loss 0.00143, valid loss 0.00219\n",
      "Training for epoch 18 done, starting evaluation\n",
      "Epoch 18 performance:\n",
      "metrics/test.rmse:  3.619\n",
      "metrics/test.rmse_pcutoff:3.619\n",
      "metrics/test.mAP:   51.403\n",
      "metrics/test.mAR:   53.333\n",
      "metrics/test.mAP_pcutoff:51.403\n",
      "metrics/test.mAR_pcutoff:53.333\n",
      "Epoch 18/200 (lr=0.0001), train loss 0.00105, valid loss 0.00235\n",
      "Training for epoch 19 done, starting evaluation\n",
      "Epoch 19 performance:\n",
      "metrics/test.rmse:  5.015\n",
      "metrics/test.rmse_pcutoff:3.226\n",
      "metrics/test.mAP:   58.926\n",
      "metrics/test.mAR:   63.333\n",
      "metrics/test.mAP_pcutoff:42.488\n",
      "metrics/test.mAR_pcutoff:43.333\n",
      "Epoch 19/200 (lr=0.0001), train loss 0.00109, valid loss 0.00226\n",
      "Training for epoch 20 done, starting evaluation\n",
      "Epoch 20 performance:\n",
      "metrics/test.rmse:  2.672\n",
      "metrics/test.rmse_pcutoff:2.672\n",
      "metrics/test.mAP:   70.875\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:70.875\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 20/200 (lr=0.0001), train loss 0.00112, valid loss 0.00179\n",
      "Training for epoch 21 done, starting evaluation\n",
      "Epoch 21 performance:\n",
      "metrics/test.rmse:  2.767\n",
      "metrics/test.rmse_pcutoff:2.767\n",
      "metrics/test.mAP:   66.312\n",
      "metrics/test.mAR:   68.333\n",
      "metrics/test.mAP_pcutoff:66.312\n",
      "metrics/test.mAR_pcutoff:68.333\n",
      "Epoch 21/200 (lr=0.0001), train loss 0.00106, valid loss 0.00134\n",
      "Training for epoch 22 done, starting evaluation\n",
      "Epoch 22 performance:\n",
      "metrics/test.rmse:  3.099\n",
      "metrics/test.rmse_pcutoff:3.099\n",
      "metrics/test.mAP:   60.322\n",
      "metrics/test.mAR:   63.333\n",
      "metrics/test.mAP_pcutoff:60.322\n",
      "metrics/test.mAR_pcutoff:63.333\n",
      "Epoch 22/200 (lr=0.0001), train loss 0.00093, valid loss 0.00145\n",
      "Training for epoch 23 done, starting evaluation\n",
      "Epoch 23 performance:\n",
      "metrics/test.rmse:  2.983\n",
      "metrics/test.rmse_pcutoff:2.983\n",
      "metrics/test.mAP:   66.955\n",
      "metrics/test.mAR:   68.333\n",
      "metrics/test.mAP_pcutoff:66.955\n",
      "metrics/test.mAR_pcutoff:68.333\n",
      "Epoch 23/200 (lr=0.0001), train loss 0.00102, valid loss 0.00172\n",
      "Training for epoch 24 done, starting evaluation\n",
      "Epoch 24 performance:\n",
      "metrics/test.rmse:  2.502\n",
      "metrics/test.rmse_pcutoff:2.502\n",
      "metrics/test.mAP:   75.569\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:75.569\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 24/200 (lr=0.0001), train loss 0.00070, valid loss 0.00121\n",
      "Training for epoch 25 done, starting evaluation\n",
      "Epoch 25 performance:\n",
      "metrics/test.rmse:  3.126\n",
      "metrics/test.rmse_pcutoff:3.126\n",
      "metrics/test.mAP:   60.322\n",
      "metrics/test.mAR:   61.667\n",
      "metrics/test.mAP_pcutoff:60.322\n",
      "metrics/test.mAR_pcutoff:61.667\n",
      "Epoch 25/200 (lr=0.0001), train loss 0.00093, valid loss 0.00157\n",
      "Training for epoch 26 done, starting evaluation\n",
      "Epoch 26 performance:\n",
      "metrics/test.rmse:  3.271\n",
      "metrics/test.rmse_pcutoff:3.271\n",
      "metrics/test.mAP:   60.322\n",
      "metrics/test.mAR:   61.667\n",
      "metrics/test.mAP_pcutoff:60.322\n",
      "metrics/test.mAR_pcutoff:61.667\n",
      "Epoch 26/200 (lr=0.0001), train loss 0.00094, valid loss 0.00195\n",
      "Training for epoch 27 done, starting evaluation\n",
      "Epoch 27 performance:\n",
      "metrics/test.rmse:  2.993\n",
      "metrics/test.rmse_pcutoff:2.993\n",
      "metrics/test.mAP:   61.163\n",
      "metrics/test.mAR:   63.333\n",
      "metrics/test.mAP_pcutoff:61.163\n",
      "metrics/test.mAR_pcutoff:63.333\n",
      "Epoch 27/200 (lr=0.0001), train loss 0.00067, valid loss 0.00147\n",
      "Training for epoch 28 done, starting evaluation\n",
      "Epoch 28 performance:\n",
      "metrics/test.rmse:  2.552\n",
      "metrics/test.rmse_pcutoff:2.552\n",
      "metrics/test.mAP:   70.842\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:70.842\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 28/200 (lr=0.0001), train loss 0.00063, valid loss 0.00131\n",
      "Training for epoch 29 done, starting evaluation\n",
      "Epoch 29 performance:\n",
      "metrics/test.rmse:  2.662\n",
      "metrics/test.rmse_pcutoff:2.662\n",
      "metrics/test.mAP:   75.330\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:75.330\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 29/200 (lr=0.0001), train loss 0.00072, valid loss 0.00124\n",
      "Training for epoch 30 done, starting evaluation\n",
      "Epoch 30 performance:\n",
      "metrics/test.rmse:  2.632\n",
      "metrics/test.rmse_pcutoff:2.632\n",
      "metrics/test.mAP:   73.267\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:73.267\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 30/200 (lr=0.0001), train loss 0.00072, valid loss 0.00123\n",
      "Training for epoch 31 done, starting evaluation\n",
      "Epoch 31 performance:\n",
      "metrics/test.rmse:  2.532\n",
      "metrics/test.rmse_pcutoff:2.532\n",
      "metrics/test.mAP:   76.733\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:76.733\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 31/200 (lr=0.0001), train loss 0.00072, valid loss 0.00118\n",
      "Training for epoch 32 done, starting evaluation\n",
      "Epoch 32 performance:\n",
      "metrics/test.rmse:  2.612\n",
      "metrics/test.rmse_pcutoff:2.612\n",
      "metrics/test.mAP:   71.361\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:71.361\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 32/200 (lr=0.0001), train loss 0.00070, valid loss 0.00141\n",
      "Training for epoch 33 done, starting evaluation\n",
      "Epoch 33 performance:\n",
      "metrics/test.rmse:  2.721\n",
      "metrics/test.rmse_pcutoff:2.742\n",
      "metrics/test.mAP:   72.203\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:65.470\n",
      "metrics/test.mAR_pcutoff:66.667\n",
      "Epoch 33/200 (lr=0.0001), train loss 0.00059, valid loss 0.00126\n",
      "Training for epoch 34 done, starting evaluation\n",
      "Epoch 34 performance:\n",
      "metrics/test.rmse:  2.727\n",
      "metrics/test.rmse_pcutoff:2.727\n",
      "metrics/test.mAP:   67.475\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:67.475\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 34/200 (lr=0.0001), train loss 0.00063, valid loss 0.00128\n",
      "Training for epoch 35 done, starting evaluation\n",
      "Epoch 35 performance:\n",
      "metrics/test.rmse:  2.389\n",
      "metrics/test.rmse_pcutoff:2.389\n",
      "metrics/test.mAP:   79.257\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:79.257\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 35/200 (lr=0.0001), train loss 0.00075, valid loss 0.00102\n",
      "Training for epoch 36 done, starting evaluation\n",
      "Epoch 36 performance:\n",
      "metrics/test.rmse:  8.494\n",
      "metrics/test.rmse_pcutoff:8.550\n",
      "metrics/test.mAP:   29.876\n",
      "metrics/test.mAR:   35.000\n",
      "metrics/test.mAP_pcutoff:2.104\n",
      "metrics/test.mAR_pcutoff:5.000\n",
      "Epoch 36/200 (lr=0.0001), train loss 0.00113, valid loss 0.00349\n",
      "Training for epoch 37 done, starting evaluation\n",
      "Epoch 37 performance:\n",
      "metrics/test.rmse:  3.110\n",
      "metrics/test.rmse_pcutoff:3.110\n",
      "metrics/test.mAP:   64.109\n",
      "metrics/test.mAR:   65.000\n",
      "metrics/test.mAP_pcutoff:64.109\n",
      "metrics/test.mAR_pcutoff:65.000\n",
      "Epoch 37/200 (lr=0.0001), train loss 0.00133, valid loss 0.00167\n",
      "Training for epoch 38 done, starting evaluation\n",
      "Epoch 38 performance:\n",
      "metrics/test.rmse:  2.777\n",
      "metrics/test.rmse_pcutoff:2.777\n",
      "metrics/test.mAP:   66.213\n",
      "metrics/test.mAR:   68.333\n",
      "metrics/test.mAP_pcutoff:66.213\n",
      "metrics/test.mAR_pcutoff:68.333\n",
      "Epoch 38/200 (lr=0.0001), train loss 0.00081, valid loss 0.00142\n",
      "Training for epoch 39 done, starting evaluation\n",
      "Epoch 39 performance:\n",
      "metrics/test.rmse:  2.739\n",
      "metrics/test.rmse_pcutoff:2.739\n",
      "metrics/test.mAP:   69.257\n",
      "metrics/test.mAR:   71.667\n",
      "metrics/test.mAP_pcutoff:69.257\n",
      "metrics/test.mAR_pcutoff:71.667\n",
      "Epoch 39/200 (lr=0.0001), train loss 0.00077, valid loss 0.00192\n",
      "Training for epoch 40 done, starting evaluation\n",
      "Epoch 40 performance:\n",
      "metrics/test.rmse:  3.255\n",
      "metrics/test.rmse_pcutoff:3.255\n",
      "metrics/test.mAP:   53.168\n",
      "metrics/test.mAR:   55.000\n",
      "metrics/test.mAP_pcutoff:53.168\n",
      "metrics/test.mAR_pcutoff:55.000\n",
      "Epoch 40/200 (lr=0.0001), train loss 0.00066, valid loss 0.00162\n",
      "Training for epoch 41 done, starting evaluation\n",
      "Epoch 41 performance:\n",
      "metrics/test.rmse:  3.089\n",
      "metrics/test.rmse_pcutoff:3.089\n",
      "metrics/test.mAP:   67.558\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:67.558\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 41/200 (lr=0.0001), train loss 0.00096, valid loss 0.00170\n",
      "Training for epoch 42 done, starting evaluation\n",
      "Epoch 42 performance:\n",
      "metrics/test.rmse:  2.942\n",
      "metrics/test.rmse_pcutoff:2.942\n",
      "metrics/test.mAP:   66.634\n",
      "metrics/test.mAR:   68.333\n",
      "metrics/test.mAP_pcutoff:66.634\n",
      "metrics/test.mAR_pcutoff:68.333\n",
      "Epoch 42/200 (lr=0.0001), train loss 0.00073, valid loss 0.00153\n",
      "Training for epoch 43 done, starting evaluation\n",
      "Epoch 43 performance:\n",
      "metrics/test.rmse:  2.648\n",
      "metrics/test.rmse_pcutoff:2.648\n",
      "metrics/test.mAP:   74.909\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:74.909\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 43/200 (lr=0.0001), train loss 0.00061, valid loss 0.00114\n",
      "Training for epoch 44 done, starting evaluation\n",
      "Epoch 44 performance:\n",
      "metrics/test.rmse:  2.955\n",
      "metrics/test.rmse_pcutoff:2.955\n",
      "metrics/test.mAP:   69.373\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:69.373\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 44/200 (lr=0.0001), train loss 0.00060, valid loss 0.00136\n",
      "Training for epoch 45 done, starting evaluation\n",
      "Epoch 45 performance:\n",
      "metrics/test.rmse:  3.686\n",
      "metrics/test.rmse_pcutoff:3.686\n",
      "metrics/test.mAP:   54.150\n",
      "metrics/test.mAR:   58.333\n",
      "metrics/test.mAP_pcutoff:54.150\n",
      "metrics/test.mAR_pcutoff:58.333\n",
      "Epoch 45/200 (lr=0.0001), train loss 0.00062, valid loss 0.00259\n",
      "Training for epoch 46 done, starting evaluation\n",
      "Epoch 46 performance:\n",
      "metrics/test.rmse:  2.843\n",
      "metrics/test.rmse_pcutoff:2.843\n",
      "metrics/test.mAP:   64.950\n",
      "metrics/test.mAR:   68.333\n",
      "metrics/test.mAP_pcutoff:64.950\n",
      "metrics/test.mAR_pcutoff:68.333\n",
      "Epoch 46/200 (lr=0.0001), train loss 0.00062, valid loss 0.00137\n",
      "Training for epoch 47 done, starting evaluation\n",
      "Epoch 47 performance:\n",
      "metrics/test.rmse:  2.674\n",
      "metrics/test.rmse_pcutoff:2.674\n",
      "metrics/test.mAP:   74.348\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:74.348\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 47/200 (lr=0.0001), train loss 0.00054, valid loss 0.00123\n",
      "Training for epoch 48 done, starting evaluation\n",
      "Epoch 48 performance:\n",
      "metrics/test.rmse:  2.823\n",
      "metrics/test.rmse_pcutoff:2.823\n",
      "metrics/test.mAP:   69.158\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:69.158\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 48/200 (lr=0.0001), train loss 0.00065, valid loss 0.00129\n",
      "Training for epoch 49 done, starting evaluation\n",
      "Epoch 49 performance:\n",
      "metrics/test.rmse:  2.249\n",
      "metrics/test.rmse_pcutoff:2.249\n",
      "metrics/test.mAP:   83.366\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:83.366\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 49/200 (lr=0.0001), train loss 0.00060, valid loss 0.00094\n",
      "Training for epoch 50 done, starting evaluation\n",
      "Epoch 50 performance:\n",
      "metrics/test.rmse:  2.229\n",
      "metrics/test.rmse_pcutoff:2.229\n",
      "metrics/test.mAP:   81.378\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.378\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 50/200 (lr=0.0001), train loss 0.00062, valid loss 0.00098\n",
      "Training for epoch 51 done, starting evaluation\n",
      "Epoch 51 performance:\n",
      "metrics/test.rmse:  2.710\n",
      "metrics/test.rmse_pcutoff:2.710\n",
      "metrics/test.mAP:   71.081\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:71.081\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 51/200 (lr=0.0001), train loss 0.00047, valid loss 0.00154\n",
      "Training for epoch 52 done, starting evaluation\n",
      "Epoch 52 performance:\n",
      "metrics/test.rmse:  2.653\n",
      "metrics/test.rmse_pcutoff:2.653\n",
      "metrics/test.mAP:   71.163\n",
      "metrics/test.mAR:   71.667\n",
      "metrics/test.mAP_pcutoff:71.163\n",
      "metrics/test.mAR_pcutoff:71.667\n",
      "Epoch 52/200 (lr=0.0001), train loss 0.00051, valid loss 0.00118\n",
      "Training for epoch 53 done, starting evaluation\n",
      "Epoch 53 performance:\n",
      "metrics/test.rmse:  2.748\n",
      "metrics/test.rmse_pcutoff:2.748\n",
      "metrics/test.mAP:   66.394\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:66.394\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 53/200 (lr=0.0001), train loss 0.00050, valid loss 0.00138\n",
      "Training for epoch 54 done, starting evaluation\n",
      "Epoch 54 performance:\n",
      "metrics/test.rmse:  2.027\n",
      "metrics/test.rmse_pcutoff:2.027\n",
      "metrics/test.mAP:   84.629\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.629\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 54/200 (lr=0.0001), train loss 0.00051, valid loss 0.00091\n",
      "Training for epoch 55 done, starting evaluation\n",
      "Epoch 55 performance:\n",
      "metrics/test.rmse:  2.294\n",
      "metrics/test.rmse_pcutoff:2.294\n",
      "metrics/test.mAP:   81.030\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.030\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 55/200 (lr=0.0001), train loss 0.00049, valid loss 0.00091\n",
      "Training for epoch 56 done, starting evaluation\n",
      "Epoch 56 performance:\n",
      "metrics/test.rmse:  2.293\n",
      "metrics/test.rmse_pcutoff:2.293\n",
      "metrics/test.mAP:   79.901\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:79.901\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 56/200 (lr=0.0001), train loss 0.00043, valid loss 0.00073\n",
      "Training for epoch 57 done, starting evaluation\n",
      "Epoch 57 performance:\n",
      "metrics/test.rmse:  2.320\n",
      "metrics/test.rmse_pcutoff:2.320\n",
      "metrics/test.mAP:   77.195\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:77.195\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 57/200 (lr=0.0001), train loss 0.00041, valid loss 0.00104\n",
      "Training for epoch 58 done, starting evaluation\n",
      "Epoch 58 performance:\n",
      "metrics/test.rmse:  2.057\n",
      "metrics/test.rmse_pcutoff:2.057\n",
      "metrics/test.mAP:   82.071\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.071\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 58/200 (lr=0.0001), train loss 0.00050, valid loss 0.00097\n",
      "Training for epoch 59 done, starting evaluation\n",
      "Epoch 59 performance:\n",
      "metrics/test.rmse:  2.172\n",
      "metrics/test.rmse_pcutoff:2.172\n",
      "metrics/test.mAP:   86.634\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:86.634\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 59/200 (lr=0.0001), train loss 0.00046, valid loss 0.00073\n",
      "Training for epoch 60 done, starting evaluation\n",
      "Epoch 60 performance:\n",
      "metrics/test.rmse:  5.519\n",
      "metrics/test.rmse_pcutoff:3.423\n",
      "metrics/test.mAP:   53.267\n",
      "metrics/test.mAR:   55.000\n",
      "metrics/test.mAP_pcutoff:44.343\n",
      "metrics/test.mAR_pcutoff:46.667\n",
      "Epoch 60/200 (lr=0.0001), train loss 0.00078, valid loss 0.00341\n",
      "Training for epoch 61 done, starting evaluation\n",
      "Epoch 61 performance:\n",
      "metrics/test.rmse:  2.840\n",
      "metrics/test.rmse_pcutoff:2.746\n",
      "metrics/test.mAP:   63.134\n",
      "metrics/test.mAR:   66.667\n",
      "metrics/test.mAP_pcutoff:52.805\n",
      "metrics/test.mAR_pcutoff:56.667\n",
      "Epoch 61/200 (lr=0.0001), train loss 0.00198, valid loss 0.00163\n",
      "Training for epoch 62 done, starting evaluation\n",
      "Epoch 62 performance:\n",
      "metrics/test.rmse:  2.533\n",
      "metrics/test.rmse_pcutoff:2.533\n",
      "metrics/test.mAP:   67.153\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:67.153\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 62/200 (lr=0.0001), train loss 0.00100, valid loss 0.00119\n",
      "Training for epoch 63 done, starting evaluation\n",
      "Epoch 63 performance:\n",
      "metrics/test.rmse:  2.731\n",
      "metrics/test.rmse_pcutoff:2.731\n",
      "metrics/test.mAP:   73.366\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:73.366\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 63/200 (lr=0.0001), train loss 0.00054, valid loss 0.00117\n",
      "Training for epoch 64 done, starting evaluation\n",
      "Epoch 64 performance:\n",
      "metrics/test.rmse:  2.714\n",
      "metrics/test.rmse_pcutoff:2.714\n",
      "metrics/test.mAP:   76.749\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:76.749\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 64/200 (lr=0.0001), train loss 0.00047, valid loss 0.00114\n",
      "Training for epoch 65 done, starting evaluation\n",
      "Epoch 65 performance:\n",
      "metrics/test.rmse:  2.220\n",
      "metrics/test.rmse_pcutoff:2.220\n",
      "metrics/test.mAP:   82.838\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.838\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 65/200 (lr=0.0001), train loss 0.00046, valid loss 0.00077\n",
      "Training for epoch 66 done, starting evaluation\n",
      "Epoch 66 performance:\n",
      "metrics/test.rmse:  2.471\n",
      "metrics/test.rmse_pcutoff:2.471\n",
      "metrics/test.mAP:   74.307\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:74.307\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 66/200 (lr=0.0001), train loss 0.00043, valid loss 0.00110\n",
      "Training for epoch 67 done, starting evaluation\n",
      "Epoch 67 performance:\n",
      "metrics/test.rmse:  2.572\n",
      "metrics/test.rmse_pcutoff:2.572\n",
      "metrics/test.mAP:   73.606\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:73.606\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 67/200 (lr=0.0001), train loss 0.00046, valid loss 0.00100\n",
      "Training for epoch 68 done, starting evaluation\n",
      "Epoch 68 performance:\n",
      "metrics/test.rmse:  2.381\n",
      "metrics/test.rmse_pcutoff:2.381\n",
      "metrics/test.mAP:   77.756\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:77.756\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 68/200 (lr=0.0001), train loss 0.00038, valid loss 0.00109\n",
      "Training for epoch 69 done, starting evaluation\n",
      "Epoch 69 performance:\n",
      "metrics/test.rmse:  2.590\n",
      "metrics/test.rmse_pcutoff:2.560\n",
      "metrics/test.mAP:   71.163\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:61.064\n",
      "metrics/test.mAR_pcutoff:63.333\n",
      "Epoch 69/200 (lr=0.0001), train loss 0.00075, valid loss 0.00157\n",
      "Training for epoch 70 done, starting evaluation\n",
      "Epoch 70 performance:\n",
      "metrics/test.rmse:  2.922\n",
      "metrics/test.rmse_pcutoff:2.922\n",
      "metrics/test.mAP:   69.084\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:69.084\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 70/200 (lr=0.0001), train loss 0.00070, valid loss 0.00193\n",
      "Training for epoch 71 done, starting evaluation\n",
      "Epoch 71 performance:\n",
      "metrics/test.rmse:  2.620\n",
      "metrics/test.rmse_pcutoff:2.620\n",
      "metrics/test.mAP:   75.371\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:75.371\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 71/200 (lr=0.0001), train loss 0.00061, valid loss 0.00110\n",
      "Training for epoch 72 done, starting evaluation\n",
      "Epoch 72 performance:\n",
      "metrics/test.rmse:  2.595\n",
      "metrics/test.rmse_pcutoff:2.595\n",
      "metrics/test.mAP:   76.172\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:76.172\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 72/200 (lr=0.0001), train loss 0.00064, valid loss 0.00123\n",
      "Training for epoch 73 done, starting evaluation\n",
      "Epoch 73 performance:\n",
      "metrics/test.rmse:  2.390\n",
      "metrics/test.rmse_pcutoff:2.390\n",
      "metrics/test.mAP:   79.488\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:79.488\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 73/200 (lr=0.0001), train loss 0.00039, valid loss 0.00104\n",
      "Training for epoch 74 done, starting evaluation\n",
      "Epoch 74 performance:\n",
      "metrics/test.rmse:  2.612\n",
      "metrics/test.rmse_pcutoff:2.612\n",
      "metrics/test.mAP:   70.000\n",
      "metrics/test.mAR:   71.667\n",
      "metrics/test.mAP_pcutoff:70.000\n",
      "metrics/test.mAR_pcutoff:71.667\n",
      "Epoch 74/200 (lr=0.0001), train loss 0.00041, valid loss 0.00122\n",
      "Training for epoch 75 done, starting evaluation\n",
      "Epoch 75 performance:\n",
      "metrics/test.rmse:  2.669\n",
      "metrics/test.rmse_pcutoff:2.669\n",
      "metrics/test.mAP:   74.455\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:74.455\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 75/200 (lr=0.0001), train loss 0.00040, valid loss 0.00123\n",
      "Training for epoch 76 done, starting evaluation\n",
      "Epoch 76 performance:\n",
      "metrics/test.rmse:  2.726\n",
      "metrics/test.rmse_pcutoff:2.726\n",
      "metrics/test.mAP:   65.965\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:65.965\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 76/200 (lr=0.0001), train loss 0.00041, valid loss 0.00130\n",
      "Training for epoch 77 done, starting evaluation\n",
      "Epoch 77 performance:\n",
      "metrics/test.rmse:  2.648\n",
      "metrics/test.rmse_pcutoff:2.648\n",
      "metrics/test.mAP:   73.861\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:73.861\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 77/200 (lr=0.0001), train loss 0.00045, valid loss 0.00133\n",
      "Training for epoch 78 done, starting evaluation\n",
      "Epoch 78 performance:\n",
      "metrics/test.rmse:  2.517\n",
      "metrics/test.rmse_pcutoff:2.517\n",
      "metrics/test.mAP:   78.771\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:78.771\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 78/200 (lr=0.0001), train loss 0.00042, valid loss 0.00115\n",
      "Training for epoch 79 done, starting evaluation\n",
      "Epoch 79 performance:\n",
      "metrics/test.rmse:  2.422\n",
      "metrics/test.rmse_pcutoff:2.422\n",
      "metrics/test.mAP:   76.312\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:76.312\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 79/200 (lr=0.0001), train loss 0.00051, valid loss 0.00098\n",
      "Training for epoch 80 done, starting evaluation\n",
      "Epoch 80 performance:\n",
      "metrics/test.rmse:  2.304\n",
      "metrics/test.rmse_pcutoff:2.304\n",
      "metrics/test.mAP:   82.541\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.541\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 80/200 (lr=0.0001), train loss 0.00040, valid loss 0.00098\n",
      "Training for epoch 81 done, starting evaluation\n",
      "Epoch 81 performance:\n",
      "metrics/test.rmse:  2.322\n",
      "metrics/test.rmse_pcutoff:2.322\n",
      "metrics/test.mAP:   80.545\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:80.545\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 81/200 (lr=0.0001), train loss 0.00034, valid loss 0.00089\n",
      "Training for epoch 82 done, starting evaluation\n",
      "Epoch 82 performance:\n",
      "metrics/test.rmse:  2.616\n",
      "metrics/test.rmse_pcutoff:2.616\n",
      "metrics/test.mAP:   71.023\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:71.023\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 82/200 (lr=0.0001), train loss 0.00046, valid loss 0.00142\n",
      "Training for epoch 83 done, starting evaluation\n",
      "Epoch 83 performance:\n",
      "metrics/test.rmse:  2.338\n",
      "metrics/test.rmse_pcutoff:2.338\n",
      "metrics/test.mAP:   76.337\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:76.337\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 83/200 (lr=0.0001), train loss 0.00046, valid loss 0.00092\n",
      "Training for epoch 84 done, starting evaluation\n",
      "Epoch 84 performance:\n",
      "metrics/test.rmse:  2.417\n",
      "metrics/test.rmse_pcutoff:2.417\n",
      "metrics/test.mAP:   80.698\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.698\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 84/200 (lr=0.0001), train loss 0.00046, valid loss 0.00093\n",
      "Training for epoch 85 done, starting evaluation\n",
      "Epoch 85 performance:\n",
      "metrics/test.rmse:  2.077\n",
      "metrics/test.rmse_pcutoff:2.077\n",
      "metrics/test.mAP:   84.990\n",
      "metrics/test.mAR:   88.333\n",
      "metrics/test.mAP_pcutoff:84.990\n",
      "metrics/test.mAR_pcutoff:88.333\n",
      "Epoch 85/200 (lr=0.0001), train loss 0.00036, valid loss 0.00080\n",
      "Training for epoch 86 done, starting evaluation\n",
      "Epoch 86 performance:\n",
      "metrics/test.rmse:  2.035\n",
      "metrics/test.rmse_pcutoff:2.035\n",
      "metrics/test.mAP:   81.218\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.218\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 86/200 (lr=0.0001), train loss 0.00033, valid loss 0.00091\n",
      "Training for epoch 87 done, starting evaluation\n",
      "Epoch 87 performance:\n",
      "metrics/test.rmse:  2.369\n",
      "metrics/test.rmse_pcutoff:2.369\n",
      "metrics/test.mAP:   79.114\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.114\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 87/200 (lr=0.0001), train loss 0.00045, valid loss 0.00093\n",
      "Training for epoch 88 done, starting evaluation\n",
      "Epoch 88 performance:\n",
      "metrics/test.rmse:  2.509\n",
      "metrics/test.rmse_pcutoff:2.509\n",
      "metrics/test.mAP:   76.749\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:76.749\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 88/200 (lr=0.0001), train loss 0.00040, valid loss 0.00108\n",
      "Training for epoch 89 done, starting evaluation\n",
      "Epoch 89 performance:\n",
      "metrics/test.rmse:  2.542\n",
      "metrics/test.rmse_pcutoff:2.542\n",
      "metrics/test.mAP:   72.104\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:72.104\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 89/200 (lr=0.0001), train loss 0.00040, valid loss 0.00104\n",
      "Training for epoch 90 done, starting evaluation\n",
      "Epoch 90 performance:\n",
      "metrics/test.rmse:  2.376\n",
      "metrics/test.rmse_pcutoff:2.376\n",
      "metrics/test.mAP:   79.784\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.784\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 90/200 (lr=0.0001), train loss 0.00040, valid loss 0.00095\n",
      "Training for epoch 91 done, starting evaluation\n",
      "Epoch 91 performance:\n",
      "metrics/test.rmse:  2.979\n",
      "metrics/test.rmse_pcutoff:2.889\n",
      "metrics/test.mAP:   62.525\n",
      "metrics/test.mAR:   65.000\n",
      "metrics/test.mAP_pcutoff:50.000\n",
      "metrics/test.mAR_pcutoff:53.333\n",
      "Epoch 91/200 (lr=0.0001), train loss 0.00036, valid loss 0.00159\n",
      "Training for epoch 92 done, starting evaluation\n",
      "Epoch 92 performance:\n",
      "metrics/test.rmse:  4.273\n",
      "metrics/test.rmse_pcutoff:3.175\n",
      "metrics/test.mAP:   41.964\n",
      "metrics/test.mAR:   50.000\n",
      "metrics/test.mAP_pcutoff:43.465\n",
      "metrics/test.mAR_pcutoff:45.000\n",
      "Epoch 92/200 (lr=0.0001), train loss 0.00073, valid loss 0.00246\n",
      "Training for epoch 93 done, starting evaluation\n",
      "Epoch 93 performance:\n",
      "metrics/test.rmse:  2.585\n",
      "metrics/test.rmse_pcutoff:2.585\n",
      "metrics/test.mAP:   72.847\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:72.847\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 93/200 (lr=0.0001), train loss 0.00045, valid loss 0.00132\n",
      "Training for epoch 94 done, starting evaluation\n",
      "Epoch 94 performance:\n",
      "metrics/test.rmse:  2.305\n",
      "metrics/test.rmse_pcutoff:2.305\n",
      "metrics/test.mAP:   82.104\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:82.104\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 94/200 (lr=0.0001), train loss 0.00038, valid loss 0.00100\n",
      "Training for epoch 95 done, starting evaluation\n",
      "Epoch 95 performance:\n",
      "metrics/test.rmse:  2.685\n",
      "metrics/test.rmse_pcutoff:2.685\n",
      "metrics/test.mAP:   77.294\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:77.294\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 95/200 (lr=0.0001), train loss 0.00046, valid loss 0.00109\n",
      "Training for epoch 96 done, starting evaluation\n",
      "Epoch 96 performance:\n",
      "metrics/test.rmse:  2.585\n",
      "metrics/test.rmse_pcutoff:2.585\n",
      "metrics/test.mAP:   72.880\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:72.880\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 96/200 (lr=0.0001), train loss 0.00038, valid loss 0.00128\n",
      "Training for epoch 97 done, starting evaluation\n",
      "Epoch 97 performance:\n",
      "metrics/test.rmse:  2.303\n",
      "metrics/test.rmse_pcutoff:2.303\n",
      "metrics/test.mAP:   80.941\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:80.941\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 97/200 (lr=0.0001), train loss 0.00029, valid loss 0.00091\n",
      "Training for epoch 98 done, starting evaluation\n",
      "Epoch 98 performance:\n",
      "metrics/test.rmse:  2.278\n",
      "metrics/test.rmse_pcutoff:2.278\n",
      "metrics/test.mAP:   81.030\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.030\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 98/200 (lr=0.0001), train loss 0.00033, valid loss 0.00097\n",
      "Training for epoch 99 done, starting evaluation\n",
      "Epoch 99 performance:\n",
      "metrics/test.rmse:  2.602\n",
      "metrics/test.rmse_pcutoff:2.602\n",
      "metrics/test.mAP:   75.479\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:75.479\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 99/200 (lr=0.0001), train loss 0.00033, valid loss 0.00128\n",
      "Training for epoch 100 done, starting evaluation\n",
      "Epoch 100 performance:\n",
      "metrics/test.rmse:  2.643\n",
      "metrics/test.rmse_pcutoff:2.643\n",
      "metrics/test.mAP:   72.071\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:72.071\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 100/200 (lr=0.0001), train loss 0.00031, valid loss 0.00119\n",
      "Training for epoch 101 done, starting evaluation\n",
      "Epoch 101 performance:\n",
      "metrics/test.rmse:  2.514\n",
      "metrics/test.rmse_pcutoff:2.514\n",
      "metrics/test.mAP:   73.086\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:73.086\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 101/200 (lr=0.0001), train loss 0.00033, valid loss 0.00135\n",
      "Training for epoch 102 done, starting evaluation\n",
      "Epoch 102 performance:\n",
      "metrics/test.rmse:  2.049\n",
      "metrics/test.rmse_pcutoff:2.049\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 102/200 (lr=0.0001), train loss 0.00033, valid loss 0.00086\n",
      "Training for epoch 103 done, starting evaluation\n",
      "Epoch 103 performance:\n",
      "metrics/test.rmse:  2.171\n",
      "metrics/test.rmse_pcutoff:2.171\n",
      "metrics/test.mAP:   81.155\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.155\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 103/200 (lr=0.0001), train loss 0.00029, valid loss 0.00088\n",
      "Training for epoch 104 done, starting evaluation\n",
      "Epoch 104 performance:\n",
      "metrics/test.rmse:  2.364\n",
      "metrics/test.rmse_pcutoff:2.364\n",
      "metrics/test.mAP:   73.079\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:73.079\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 104/200 (lr=0.0001), train loss 0.00035, valid loss 0.00098\n",
      "Training for epoch 105 done, starting evaluation\n",
      "Epoch 105 performance:\n",
      "metrics/test.rmse:  2.274\n",
      "metrics/test.rmse_pcutoff:2.274\n",
      "metrics/test.mAP:   76.370\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:76.370\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 105/200 (lr=0.0001), train loss 0.00029, valid loss 0.00110\n",
      "Training for epoch 106 done, starting evaluation\n",
      "Epoch 106 performance:\n",
      "metrics/test.rmse:  2.385\n",
      "metrics/test.rmse_pcutoff:2.385\n",
      "metrics/test.mAP:   76.733\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:76.733\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 106/200 (lr=0.0001), train loss 0.00027, valid loss 0.00099\n",
      "Training for epoch 107 done, starting evaluation\n",
      "Epoch 107 performance:\n",
      "metrics/test.rmse:  2.531\n",
      "metrics/test.rmse_pcutoff:2.531\n",
      "metrics/test.mAP:   74.208\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:74.208\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 107/200 (lr=0.0001), train loss 0.00028, valid loss 0.00116\n",
      "Training for epoch 108 done, starting evaluation\n",
      "Epoch 108 performance:\n",
      "metrics/test.rmse:  3.635\n",
      "metrics/test.rmse_pcutoff:3.635\n",
      "metrics/test.mAP:   58.960\n",
      "metrics/test.mAR:   61.667\n",
      "metrics/test.mAP_pcutoff:58.960\n",
      "metrics/test.mAR_pcutoff:61.667\n",
      "Epoch 108/200 (lr=0.0001), train loss 0.00048, valid loss 0.00190\n",
      "Training for epoch 109 done, starting evaluation\n",
      "Epoch 109 performance:\n",
      "metrics/test.rmse:  2.688\n",
      "metrics/test.rmse_pcutoff:2.688\n",
      "metrics/test.mAP:   70.421\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:70.421\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 109/200 (lr=0.0001), train loss 0.00039, valid loss 0.00128\n",
      "Training for epoch 110 done, starting evaluation\n",
      "Epoch 110 performance:\n",
      "metrics/test.rmse:  2.183\n",
      "metrics/test.rmse_pcutoff:2.183\n",
      "metrics/test.mAP:   85.512\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:85.512\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 110/200 (lr=0.0001), train loss 0.00033, valid loss 0.00087\n",
      "Training for epoch 111 done, starting evaluation\n",
      "Epoch 111 performance:\n",
      "metrics/test.rmse:  3.082\n",
      "metrics/test.rmse_pcutoff:3.082\n",
      "metrics/test.mAP:   62.665\n",
      "metrics/test.mAR:   65.000\n",
      "metrics/test.mAP_pcutoff:62.665\n",
      "metrics/test.mAR_pcutoff:65.000\n",
      "Epoch 111/200 (lr=0.0001), train loss 0.00032, valid loss 0.00155\n",
      "Training for epoch 112 done, starting evaluation\n",
      "Epoch 112 performance:\n",
      "metrics/test.rmse:  2.554\n",
      "metrics/test.rmse_pcutoff:2.554\n",
      "metrics/test.mAP:   70.281\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:70.281\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 112/200 (lr=0.0001), train loss 0.00028, valid loss 0.00117\n",
      "Training for epoch 113 done, starting evaluation\n",
      "Epoch 113 performance:\n",
      "metrics/test.rmse:  2.406\n",
      "metrics/test.rmse_pcutoff:2.345\n",
      "metrics/test.mAP:   75.891\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:70.842\n",
      "metrics/test.mAR_pcutoff:71.667\n",
      "Epoch 113/200 (lr=0.0001), train loss 0.00039, valid loss 0.00115\n",
      "Training for epoch 114 done, starting evaluation\n",
      "Epoch 114 performance:\n",
      "metrics/test.rmse:  2.965\n",
      "metrics/test.rmse_pcutoff:2.965\n",
      "metrics/test.mAP:   66.073\n",
      "metrics/test.mAR:   68.333\n",
      "metrics/test.mAP_pcutoff:66.073\n",
      "metrics/test.mAR_pcutoff:68.333\n",
      "Epoch 114/200 (lr=0.0001), train loss 0.00069, valid loss 0.00149\n",
      "Training for epoch 115 done, starting evaluation\n",
      "Epoch 115 performance:\n",
      "metrics/test.rmse:  2.334\n",
      "metrics/test.rmse_pcutoff:2.429\n",
      "metrics/test.mAP:   71.540\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:60.281\n",
      "metrics/test.mAR_pcutoff:63.333\n",
      "Epoch 115/200 (lr=0.0001), train loss 0.00124, valid loss 0.00137\n",
      "Training for epoch 116 done, starting evaluation\n",
      "Epoch 116 performance:\n",
      "metrics/test.rmse:  2.735\n",
      "metrics/test.rmse_pcutoff:2.735\n",
      "metrics/test.mAP:   73.066\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:73.066\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 116/200 (lr=0.0001), train loss 0.00111, valid loss 0.00116\n",
      "Training for epoch 117 done, starting evaluation\n",
      "Epoch 117 performance:\n",
      "metrics/test.rmse:  2.091\n",
      "metrics/test.rmse_pcutoff:2.091\n",
      "metrics/test.mAP:   84.330\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.330\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 117/200 (lr=0.0001), train loss 0.00067, valid loss 0.00086\n",
      "Training for epoch 118 done, starting evaluation\n",
      "Epoch 118 performance:\n",
      "metrics/test.rmse:  1.842\n",
      "metrics/test.rmse_pcutoff:1.842\n",
      "metrics/test.mAP:   84.906\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.906\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 118/200 (lr=0.0001), train loss 0.00040, valid loss 0.00067\n",
      "Training for epoch 119 done, starting evaluation\n",
      "Epoch 119 performance:\n",
      "metrics/test.rmse:  2.929\n",
      "metrics/test.rmse_pcutoff:2.732\n",
      "metrics/test.mAP:   67.558\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:68.960\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 119/200 (lr=0.0001), train loss 0.00039, valid loss 0.00137\n",
      "Training for epoch 120 done, starting evaluation\n",
      "Epoch 120 performance:\n",
      "metrics/test.rmse:  1.769\n",
      "metrics/test.rmse_pcutoff:1.769\n",
      "metrics/test.mAP:   90.277\n",
      "metrics/test.mAR:   91.667\n",
      "metrics/test.mAP_pcutoff:90.277\n",
      "metrics/test.mAR_pcutoff:91.667\n",
      "Epoch 120/200 (lr=0.0001), train loss 0.00030, valid loss 0.00066\n",
      "Training for epoch 121 done, starting evaluation\n",
      "Epoch 121 performance:\n",
      "metrics/test.rmse:  2.271\n",
      "metrics/test.rmse_pcutoff:2.271\n",
      "metrics/test.mAP:   73.035\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:73.035\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 121/200 (lr=0.0001), train loss 0.00038, valid loss 0.00094\n",
      "Training for epoch 122 done, starting evaluation\n",
      "Epoch 122 performance:\n",
      "metrics/test.rmse:  1.920\n",
      "metrics/test.rmse_pcutoff:1.920\n",
      "metrics/test.mAP:   84.990\n",
      "metrics/test.mAR:   88.333\n",
      "metrics/test.mAP_pcutoff:84.990\n",
      "metrics/test.mAR_pcutoff:88.333\n",
      "Epoch 122/200 (lr=0.0001), train loss 0.00029, valid loss 0.00076\n",
      "Training for epoch 123 done, starting evaluation\n",
      "Epoch 123 performance:\n",
      "metrics/test.rmse:  2.290\n",
      "metrics/test.rmse_pcutoff:2.290\n",
      "metrics/test.mAP:   79.624\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.624\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 123/200 (lr=0.0001), train loss 0.00031, valid loss 0.00094\n",
      "Training for epoch 124 done, starting evaluation\n",
      "Epoch 124 performance:\n",
      "metrics/test.rmse:  2.497\n",
      "metrics/test.rmse_pcutoff:2.497\n",
      "metrics/test.mAP:   77.941\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:77.941\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 124/200 (lr=0.0001), train loss 0.00033, valid loss 0.00104\n",
      "Training for epoch 125 done, starting evaluation\n",
      "Epoch 125 performance:\n",
      "metrics/test.rmse:  2.030\n",
      "metrics/test.rmse_pcutoff:2.030\n",
      "metrics/test.mAP:   86.401\n",
      "metrics/test.mAR:   88.333\n",
      "metrics/test.mAP_pcutoff:86.401\n",
      "metrics/test.mAR_pcutoff:88.333\n",
      "Epoch 125/200 (lr=0.0001), train loss 0.00027, valid loss 0.00074\n",
      "Training for epoch 126 done, starting evaluation\n",
      "Epoch 126 performance:\n",
      "metrics/test.rmse:  2.129\n",
      "metrics/test.rmse_pcutoff:2.129\n",
      "metrics/test.mAP:   82.802\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.802\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 126/200 (lr=0.0001), train loss 0.00026, valid loss 0.00077\n",
      "Training for epoch 127 done, starting evaluation\n",
      "Epoch 127 performance:\n",
      "metrics/test.rmse:  3.852\n",
      "metrics/test.rmse_pcutoff:2.820\n",
      "metrics/test.mAP:   53.149\n",
      "metrics/test.mAR:   63.333\n",
      "metrics/test.mAP_pcutoff:59.340\n",
      "metrics/test.mAR_pcutoff:61.667\n",
      "Epoch 127/200 (lr=0.0001), train loss 0.00061, valid loss 0.00155\n",
      "Training for epoch 128 done, starting evaluation\n",
      "Epoch 128 performance:\n",
      "metrics/test.rmse:  2.292\n",
      "metrics/test.rmse_pcutoff:2.292\n",
      "metrics/test.mAP:   78.977\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:78.977\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 128/200 (lr=0.0001), train loss 0.00046, valid loss 0.00095\n",
      "Training for epoch 129 done, starting evaluation\n",
      "Epoch 129 performance:\n",
      "metrics/test.rmse:  2.076\n",
      "metrics/test.rmse_pcutoff:2.076\n",
      "metrics/test.mAP:   84.348\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.348\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 129/200 (lr=0.0001), train loss 0.00039, valid loss 0.00076\n",
      "Training for epoch 130 done, starting evaluation\n",
      "Epoch 130 performance:\n",
      "metrics/test.rmse:  2.070\n",
      "metrics/test.rmse_pcutoff:2.070\n",
      "metrics/test.mAP:   82.946\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:82.946\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 130/200 (lr=0.0001), train loss 0.00030, valid loss 0.00073\n",
      "Training for epoch 131 done, starting evaluation\n",
      "Epoch 131 performance:\n",
      "metrics/test.rmse:  2.138\n",
      "metrics/test.rmse_pcutoff:2.138\n",
      "metrics/test.mAP:   78.594\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:78.594\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 131/200 (lr=0.0001), train loss 0.00029, valid loss 0.00078\n",
      "Training for epoch 132 done, starting evaluation\n",
      "Epoch 132 performance:\n",
      "metrics/test.rmse:  1.973\n",
      "metrics/test.rmse_pcutoff:1.973\n",
      "metrics/test.mAP:   84.906\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.906\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 132/200 (lr=0.0001), train loss 0.00028, valid loss 0.00070\n",
      "Training for epoch 133 done, starting evaluation\n",
      "Epoch 133 performance:\n",
      "metrics/test.rmse:  2.131\n",
      "metrics/test.rmse_pcutoff:2.131\n",
      "metrics/test.mAP:   82.946\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.946\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 133/200 (lr=0.0001), train loss 0.00022, valid loss 0.00077\n",
      "Training for epoch 134 done, starting evaluation\n",
      "Epoch 134 performance:\n",
      "metrics/test.rmse:  2.157\n",
      "metrics/test.rmse_pcutoff:2.157\n",
      "metrics/test.mAP:   79.752\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.752\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 134/200 (lr=0.0001), train loss 0.00036, valid loss 0.00095\n",
      "Training for epoch 135 done, starting evaluation\n",
      "Epoch 135 performance:\n",
      "metrics/test.rmse:  1.824\n",
      "metrics/test.rmse_pcutoff:1.824\n",
      "metrics/test.mAP:   86.589\n",
      "metrics/test.mAR:   88.333\n",
      "metrics/test.mAP_pcutoff:86.589\n",
      "metrics/test.mAR_pcutoff:88.333\n",
      "Epoch 135/200 (lr=0.0001), train loss 0.00027, valid loss 0.00072\n",
      "Training for epoch 136 done, starting evaluation\n",
      "Epoch 136 performance:\n",
      "metrics/test.rmse:  2.031\n",
      "metrics/test.rmse_pcutoff:2.031\n",
      "metrics/test.mAP:   85.701\n",
      "metrics/test.mAR:   88.333\n",
      "metrics/test.mAP_pcutoff:85.701\n",
      "metrics/test.mAR_pcutoff:88.333\n",
      "Epoch 136/200 (lr=0.0001), train loss 0.00026, valid loss 0.00085\n",
      "Training for epoch 137 done, starting evaluation\n",
      "Epoch 137 performance:\n",
      "metrics/test.rmse:  3.186\n",
      "metrics/test.rmse_pcutoff:3.143\n",
      "metrics/test.mAP:   61.683\n",
      "metrics/test.mAR:   63.333\n",
      "metrics/test.mAP_pcutoff:44.271\n",
      "metrics/test.mAR_pcutoff:46.667\n",
      "Epoch 137/200 (lr=0.0001), train loss 0.00045, valid loss 0.00197\n",
      "Training for epoch 138 done, starting evaluation\n",
      "Epoch 138 performance:\n",
      "metrics/test.rmse:  2.509\n",
      "metrics/test.rmse_pcutoff:2.509\n",
      "metrics/test.mAP:   77.475\n",
      "metrics/test.mAR:   78.333\n",
      "metrics/test.mAP_pcutoff:77.475\n",
      "metrics/test.mAR_pcutoff:78.333\n",
      "Epoch 138/200 (lr=0.0001), train loss 0.00059, valid loss 0.00125\n",
      "Training for epoch 139 done, starting evaluation\n",
      "Epoch 139 performance:\n",
      "metrics/test.rmse:  2.410\n",
      "metrics/test.rmse_pcutoff:2.410\n",
      "metrics/test.mAP:   72.203\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:72.203\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 139/200 (lr=0.0001), train loss 0.00040, valid loss 0.00106\n",
      "Training for epoch 140 done, starting evaluation\n",
      "Epoch 140 performance:\n",
      "metrics/test.rmse:  1.978\n",
      "metrics/test.rmse_pcutoff:1.978\n",
      "metrics/test.mAP:   85.980\n",
      "metrics/test.mAR:   88.333\n",
      "metrics/test.mAP_pcutoff:85.980\n",
      "metrics/test.mAR_pcutoff:88.333\n",
      "Epoch 140/200 (lr=0.0001), train loss 0.00029, valid loss 0.00065\n",
      "Training for epoch 141 done, starting evaluation\n",
      "Epoch 141 performance:\n",
      "metrics/test.rmse:  2.471\n",
      "metrics/test.rmse_pcutoff:2.471\n",
      "metrics/test.mAP:   71.960\n",
      "metrics/test.mAR:   75.000\n",
      "metrics/test.mAP_pcutoff:71.960\n",
      "metrics/test.mAR_pcutoff:75.000\n",
      "Epoch 141/200 (lr=0.0001), train loss 0.00027, valid loss 0.00099\n",
      "Training for epoch 142 done, starting evaluation\n",
      "Epoch 142 performance:\n",
      "metrics/test.rmse:  2.422\n",
      "metrics/test.rmse_pcutoff:2.422\n",
      "metrics/test.mAP:   73.647\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:73.647\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 142/200 (lr=0.0001), train loss 0.00025, valid loss 0.00101\n",
      "Training for epoch 143 done, starting evaluation\n",
      "Epoch 143 performance:\n",
      "metrics/test.rmse:  2.429\n",
      "metrics/test.rmse_pcutoff:2.429\n",
      "metrics/test.mAP:   73.787\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:73.787\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 143/200 (lr=0.0001), train loss 0.00028, valid loss 0.00112\n",
      "Training for epoch 144 done, starting evaluation\n",
      "Epoch 144 performance:\n",
      "metrics/test.rmse:  2.630\n",
      "metrics/test.rmse_pcutoff:2.630\n",
      "metrics/test.mAP:   69.761\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:69.761\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 144/200 (lr=0.0001), train loss 0.00026, valid loss 0.00135\n",
      "Training for epoch 145 done, starting evaluation\n",
      "Epoch 145 performance:\n",
      "metrics/test.rmse:  1.935\n",
      "metrics/test.rmse_pcutoff:1.935\n",
      "metrics/test.mAP:   85.139\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:85.139\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 145/200 (lr=0.0001), train loss 0.00028, valid loss 0.00068\n",
      "Training for epoch 146 done, starting evaluation\n",
      "Epoch 146 performance:\n",
      "metrics/test.rmse:  1.951\n",
      "metrics/test.rmse_pcutoff:1.951\n",
      "metrics/test.mAP:   85.487\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:85.487\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 146/200 (lr=0.0001), train loss 0.00025, valid loss 0.00076\n",
      "Training for epoch 147 done, starting evaluation\n",
      "Epoch 147 performance:\n",
      "metrics/test.rmse:  2.139\n",
      "metrics/test.rmse_pcutoff:2.139\n",
      "metrics/test.mAP:   84.208\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:84.208\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 147/200 (lr=0.0001), train loss 0.00025, valid loss 0.00081\n",
      "Training for epoch 148 done, starting evaluation\n",
      "Epoch 148 performance:\n",
      "metrics/test.rmse:  3.486\n",
      "metrics/test.rmse_pcutoff:3.486\n",
      "metrics/test.mAP:   66.955\n",
      "metrics/test.mAR:   70.000\n",
      "metrics/test.mAP_pcutoff:66.955\n",
      "metrics/test.mAR_pcutoff:70.000\n",
      "Epoch 148/200 (lr=0.0001), train loss 0.00023, valid loss 0.00167\n",
      "Training for epoch 149 done, starting evaluation\n",
      "Epoch 149 performance:\n",
      "metrics/test.rmse:  2.399\n",
      "metrics/test.rmse_pcutoff:2.399\n",
      "metrics/test.mAP:   78.177\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:78.177\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 149/200 (lr=0.0001), train loss 0.00037, valid loss 0.00115\n",
      "Training for epoch 150 done, starting evaluation\n",
      "Epoch 150 performance:\n",
      "metrics/test.rmse:  1.788\n",
      "metrics/test.rmse_pcutoff:1.788\n",
      "metrics/test.mAP:   88.505\n",
      "metrics/test.mAR:   90.000\n",
      "metrics/test.mAP_pcutoff:88.505\n",
      "metrics/test.mAR_pcutoff:90.000\n",
      "Epoch 150/200 (lr=0.0001), train loss 0.00035, valid loss 0.00071\n",
      "Training for epoch 151 done, starting evaluation\n",
      "Epoch 151 performance:\n",
      "metrics/test.rmse:  2.163\n",
      "metrics/test.rmse_pcutoff:2.163\n",
      "metrics/test.mAP:   82.292\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:82.292\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 151/200 (lr=0.0001), train loss 0.00033, valid loss 0.00083\n",
      "Training for epoch 152 done, starting evaluation\n",
      "Epoch 152 performance:\n",
      "metrics/test.rmse:  2.210\n",
      "metrics/test.rmse_pcutoff:2.210\n",
      "metrics/test.mAP:   82.104\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:82.104\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 152/200 (lr=0.0001), train loss 0.00036, valid loss 0.00086\n",
      "Training for epoch 153 done, starting evaluation\n",
      "Epoch 153 performance:\n",
      "metrics/test.rmse:  2.150\n",
      "metrics/test.rmse_pcutoff:2.150\n",
      "metrics/test.mAP:   83.644\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:83.644\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 153/200 (lr=0.0001), train loss 0.00028, valid loss 0.00084\n",
      "Training for epoch 154 done, starting evaluation\n",
      "Epoch 154 performance:\n",
      "metrics/test.rmse:  2.188\n",
      "metrics/test.rmse_pcutoff:2.188\n",
      "metrics/test.mAP:   78.738\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:78.738\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 154/200 (lr=0.0001), train loss 0.00024, valid loss 0.00071\n",
      "Training for epoch 155 done, starting evaluation\n",
      "Epoch 155 performance:\n",
      "metrics/test.rmse:  2.072\n",
      "metrics/test.rmse_pcutoff:2.072\n",
      "metrics/test.mAP:   87.663\n",
      "metrics/test.mAR:   88.333\n",
      "metrics/test.mAP_pcutoff:87.663\n",
      "metrics/test.mAR_pcutoff:88.333\n",
      "Epoch 155/200 (lr=0.0001), train loss 0.00023, valid loss 0.00079\n",
      "Training for epoch 156 done, starting evaluation\n",
      "Epoch 156 performance:\n",
      "metrics/test.rmse:  2.171\n",
      "metrics/test.rmse_pcutoff:2.171\n",
      "metrics/test.mAP:   79.620\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.620\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 156/200 (lr=0.0001), train loss 0.00038, valid loss 0.00088\n",
      "Training for epoch 157 done, starting evaluation\n",
      "Epoch 157 performance:\n",
      "metrics/test.rmse:  2.656\n",
      "metrics/test.rmse_pcutoff:2.656\n",
      "metrics/test.mAP:   70.322\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:70.322\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 157/200 (lr=0.0001), train loss 0.00047, valid loss 0.00113\n",
      "Training for epoch 158 done, starting evaluation\n",
      "Epoch 158 performance:\n",
      "metrics/test.rmse:  2.592\n",
      "metrics/test.rmse_pcutoff:2.592\n",
      "metrics/test.mAP:   68.771\n",
      "metrics/test.mAR:   73.333\n",
      "metrics/test.mAP_pcutoff:68.771\n",
      "metrics/test.mAR_pcutoff:73.333\n",
      "Epoch 158/200 (lr=0.0001), train loss 0.00033, valid loss 0.00152\n",
      "Training for epoch 159 done, starting evaluation\n",
      "Epoch 159 performance:\n",
      "metrics/test.rmse:  2.877\n",
      "metrics/test.rmse_pcutoff:2.877\n",
      "metrics/test.mAP:   66.774\n",
      "metrics/test.mAR:   68.333\n",
      "metrics/test.mAP_pcutoff:66.774\n",
      "metrics/test.mAR_pcutoff:68.333\n",
      "Epoch 159/200 (lr=0.0001), train loss 0.00170, valid loss 0.00141\n",
      "Training for epoch 160 done, starting evaluation\n",
      "Epoch 160 performance:\n",
      "metrics/test.rmse:  3.051\n",
      "metrics/test.rmse_pcutoff:3.196\n",
      "metrics/test.mAP:   60.099\n",
      "metrics/test.mAR:   61.667\n",
      "metrics/test.mAP_pcutoff:53.564\n",
      "metrics/test.mAR_pcutoff:53.333\n",
      "Epoch 160/200 (lr=1e-05), train loss 0.00061, valid loss 0.00179\n",
      "Training for epoch 161 done, starting evaluation\n",
      "Epoch 161 performance:\n",
      "metrics/test.rmse:  2.432\n",
      "metrics/test.rmse_pcutoff:2.432\n",
      "metrics/test.mAP:   73.606\n",
      "metrics/test.mAR:   76.667\n",
      "metrics/test.mAP_pcutoff:73.606\n",
      "metrics/test.mAR_pcutoff:76.667\n",
      "Epoch 161/200 (lr=1e-05), train loss 0.00044, valid loss 0.00107\n",
      "Training for epoch 162 done, starting evaluation\n",
      "Epoch 162 performance:\n",
      "metrics/test.rmse:  2.288\n",
      "metrics/test.rmse_pcutoff:2.288\n",
      "metrics/test.mAP:   79.571\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.571\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 162/200 (lr=1e-05), train loss 0.00032, valid loss 0.00098\n",
      "Training for epoch 163 done, starting evaluation\n",
      "Epoch 163 performance:\n",
      "metrics/test.rmse:  2.300\n",
      "metrics/test.rmse_pcutoff:2.300\n",
      "metrics/test.mAP:   76.625\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:76.625\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 163/200 (lr=1e-05), train loss 0.00028, valid loss 0.00098\n",
      "Training for epoch 164 done, starting evaluation\n",
      "Epoch 164 performance:\n",
      "metrics/test.rmse:  2.265\n",
      "metrics/test.rmse_pcutoff:2.265\n",
      "metrics/test.mAP:   76.625\n",
      "metrics/test.mAR:   80.000\n",
      "metrics/test.mAP_pcutoff:76.625\n",
      "metrics/test.mAR_pcutoff:80.000\n",
      "Epoch 164/200 (lr=1e-05), train loss 0.00028, valid loss 0.00095\n",
      "Training for epoch 165 done, starting evaluation\n",
      "Epoch 165 performance:\n",
      "metrics/test.rmse:  2.240\n",
      "metrics/test.rmse_pcutoff:2.240\n",
      "metrics/test.mAP:   79.571\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.571\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 165/200 (lr=1e-05), train loss 0.00026, valid loss 0.00092\n",
      "Training for epoch 166 done, starting evaluation\n",
      "Epoch 166 performance:\n",
      "metrics/test.rmse:  2.246\n",
      "metrics/test.rmse_pcutoff:2.246\n",
      "metrics/test.mAP:   78.977\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:78.977\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 166/200 (lr=1e-05), train loss 0.00023, valid loss 0.00088\n",
      "Training for epoch 167 done, starting evaluation\n",
      "Epoch 167 performance:\n",
      "metrics/test.rmse:  2.233\n",
      "metrics/test.rmse_pcutoff:2.233\n",
      "metrics/test.mAP:   81.922\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.922\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 167/200 (lr=1e-05), train loss 0.00021, valid loss 0.00089\n",
      "Training for epoch 168 done, starting evaluation\n",
      "Epoch 168 performance:\n",
      "metrics/test.rmse:  2.253\n",
      "metrics/test.rmse_pcutoff:2.253\n",
      "metrics/test.mAP:   81.922\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.922\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 168/200 (lr=1e-05), train loss 0.00021, valid loss 0.00091\n",
      "Training for epoch 169 done, starting evaluation\n",
      "Epoch 169 performance:\n",
      "metrics/test.rmse:  2.184\n",
      "metrics/test.rmse_pcutoff:2.184\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 169/200 (lr=1e-05), train loss 0.00021, valid loss 0.00086\n",
      "Training for epoch 170 done, starting evaluation\n",
      "Epoch 170 performance:\n",
      "metrics/test.rmse:  2.207\n",
      "metrics/test.rmse_pcutoff:2.207\n",
      "metrics/test.mAP:   83.886\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:83.886\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 170/200 (lr=1e-05), train loss 0.00024, valid loss 0.00085\n",
      "Training for epoch 171 done, starting evaluation\n",
      "Epoch 171 performance:\n",
      "metrics/test.rmse:  2.197\n",
      "metrics/test.rmse_pcutoff:2.197\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 171/200 (lr=1e-05), train loss 0.00024, valid loss 0.00092\n",
      "Training for epoch 172 done, starting evaluation\n",
      "Epoch 172 performance:\n",
      "metrics/test.rmse:  2.212\n",
      "metrics/test.rmse_pcutoff:2.212\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 172/200 (lr=1e-05), train loss 0.00022, valid loss 0.00092\n",
      "Training for epoch 173 done, starting evaluation\n",
      "Epoch 173 performance:\n",
      "metrics/test.rmse:  2.207\n",
      "metrics/test.rmse_pcutoff:2.207\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 173/200 (lr=1e-05), train loss 0.00019, valid loss 0.00090\n",
      "Training for epoch 174 done, starting evaluation\n",
      "Epoch 174 performance:\n",
      "metrics/test.rmse:  2.228\n",
      "metrics/test.rmse_pcutoff:2.228\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 174/200 (lr=1e-05), train loss 0.00019, valid loss 0.00091\n",
      "Training for epoch 175 done, starting evaluation\n",
      "Epoch 175 performance:\n",
      "metrics/test.rmse:  2.140\n",
      "metrics/test.rmse_pcutoff:2.140\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 175/200 (lr=1e-05), train loss 0.00020, valid loss 0.00088\n",
      "Training for epoch 176 done, starting evaluation\n",
      "Epoch 176 performance:\n",
      "metrics/test.rmse:  2.112\n",
      "metrics/test.rmse_pcutoff:2.112\n",
      "metrics/test.mAP:   84.942\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.942\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 176/200 (lr=1e-05), train loss 0.00020, valid loss 0.00088\n",
      "Training for epoch 177 done, starting evaluation\n",
      "Epoch 177 performance:\n",
      "metrics/test.rmse:  2.135\n",
      "metrics/test.rmse_pcutoff:2.135\n",
      "metrics/test.mAP:   84.942\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.942\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 177/200 (lr=1e-05), train loss 0.00019, valid loss 0.00086\n",
      "Training for epoch 178 done, starting evaluation\n",
      "Epoch 178 performance:\n",
      "metrics/test.rmse:  2.107\n",
      "metrics/test.rmse_pcutoff:2.107\n",
      "metrics/test.mAP:   84.035\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.035\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 178/200 (lr=1e-05), train loss 0.00020, valid loss 0.00087\n",
      "Training for epoch 179 done, starting evaluation\n",
      "Epoch 179 performance:\n",
      "metrics/test.rmse:  2.113\n",
      "metrics/test.rmse_pcutoff:2.113\n",
      "metrics/test.mAP:   81.931\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:81.931\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 179/200 (lr=1e-05), train loss 0.00018, valid loss 0.00087\n",
      "Training for epoch 180 done, starting evaluation\n",
      "Epoch 180 performance:\n",
      "metrics/test.rmse:  2.188\n",
      "metrics/test.rmse_pcutoff:2.188\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 180/200 (lr=1e-05), train loss 0.00017, valid loss 0.00091\n",
      "Training for epoch 181 done, starting evaluation\n",
      "Epoch 181 performance:\n",
      "metrics/test.rmse:  2.098\n",
      "metrics/test.rmse_pcutoff:2.098\n",
      "metrics/test.mAP:   84.035\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.035\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 181/200 (lr=1e-05), train loss 0.00022, valid loss 0.00085\n",
      "Training for epoch 182 done, starting evaluation\n",
      "Epoch 182 performance:\n",
      "metrics/test.rmse:  2.175\n",
      "metrics/test.rmse_pcutoff:2.175\n",
      "metrics/test.mAP:   82.979\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:82.979\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 182/200 (lr=1e-05), train loss 0.00020, valid loss 0.00088\n",
      "Training for epoch 183 done, starting evaluation\n",
      "Epoch 183 performance:\n",
      "metrics/test.rmse:  2.098\n",
      "metrics/test.rmse_pcutoff:2.098\n",
      "metrics/test.mAP:   84.035\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.035\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 183/200 (lr=1e-05), train loss 0.00018, valid loss 0.00086\n",
      "Training for epoch 184 done, starting evaluation\n",
      "Epoch 184 performance:\n",
      "metrics/test.rmse:  2.096\n",
      "metrics/test.rmse_pcutoff:2.096\n",
      "metrics/test.mAP:   84.035\n",
      "metrics/test.mAR:   86.667\n",
      "metrics/test.mAP_pcutoff:84.035\n",
      "metrics/test.mAR_pcutoff:86.667\n",
      "Epoch 184/200 (lr=1e-05), train loss 0.00021, valid loss 0.00088\n",
      "Training for epoch 185 done, starting evaluation\n",
      "Epoch 185 performance:\n",
      "metrics/test.rmse:  2.130\n",
      "metrics/test.rmse_pcutoff:2.130\n",
      "metrics/test.mAP:   81.015\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.015\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 185/200 (lr=1e-05), train loss 0.00017, valid loss 0.00089\n",
      "Training for epoch 186 done, starting evaluation\n",
      "Epoch 186 performance:\n",
      "metrics/test.rmse:  2.200\n",
      "metrics/test.rmse_pcutoff:2.200\n",
      "metrics/test.mAP:   79.959\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.959\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 186/200 (lr=1e-05), train loss 0.00017, valid loss 0.00092\n",
      "Training for epoch 187 done, starting evaluation\n",
      "Epoch 187 performance:\n",
      "metrics/test.rmse:  2.147\n",
      "metrics/test.rmse_pcutoff:2.147\n",
      "metrics/test.mAP:   79.959\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:79.959\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 187/200 (lr=1e-05), train loss 0.00023, valid loss 0.00090\n",
      "Training for epoch 188 done, starting evaluation\n",
      "Epoch 188 performance:\n",
      "metrics/test.rmse:  2.172\n",
      "metrics/test.rmse_pcutoff:2.172\n",
      "metrics/test.mAP:   81.015\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:81.015\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 188/200 (lr=1e-05), train loss 0.00017, valid loss 0.00095\n",
      "Training for epoch 189 done, starting evaluation\n",
      "Epoch 189 performance:\n",
      "metrics/test.rmse:  2.070\n",
      "metrics/test.rmse_pcutoff:2.070\n",
      "metrics/test.mAP:   83.886\n",
      "metrics/test.mAR:   85.000\n",
      "metrics/test.mAP_pcutoff:83.886\n",
      "metrics/test.mAR_pcutoff:85.000\n",
      "Epoch 189/200 (lr=1e-05), train loss 0.00014, valid loss 0.00082\n",
      "Training for epoch 190 done, starting evaluation\n",
      "Epoch 190 performance:\n",
      "metrics/test.rmse:  2.159\n",
      "metrics/test.rmse_pcutoff:2.159\n",
      "metrics/test.mAP:   78.911\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:78.911\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 190/200 (lr=1e-06), train loss 0.00017, valid loss 0.00093\n",
      "Training for epoch 191 done, starting evaluation\n",
      "Epoch 191 performance:\n",
      "metrics/test.rmse:  2.143\n",
      "metrics/test.rmse_pcutoff:2.143\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 191/200 (lr=1e-06), train loss 0.00015, valid loss 0.00092\n",
      "Training for epoch 192 done, starting evaluation\n",
      "Epoch 192 performance:\n",
      "metrics/test.rmse:  2.142\n",
      "metrics/test.rmse_pcutoff:2.142\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 192/200 (lr=1e-06), train loss 0.00016, valid loss 0.00093\n",
      "Training for epoch 193 done, starting evaluation\n",
      "Epoch 193 performance:\n",
      "metrics/test.rmse:  2.144\n",
      "metrics/test.rmse_pcutoff:2.144\n",
      "metrics/test.mAP:   78.911\n",
      "metrics/test.mAR:   81.667\n",
      "metrics/test.mAP_pcutoff:78.911\n",
      "metrics/test.mAR_pcutoff:81.667\n",
      "Epoch 193/200 (lr=1e-06), train loss 0.00015, valid loss 0.00092\n",
      "Training for epoch 194 done, starting evaluation\n",
      "Epoch 194 performance:\n",
      "metrics/test.rmse:  2.125\n",
      "metrics/test.rmse_pcutoff:2.125\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 194/200 (lr=1e-06), train loss 0.00015, valid loss 0.00090\n",
      "Training for epoch 195 done, starting evaluation\n",
      "Epoch 195 performance:\n",
      "metrics/test.rmse:  2.104\n",
      "metrics/test.rmse_pcutoff:2.104\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 195/200 (lr=1e-06), train loss 0.00014, valid loss 0.00089\n",
      "Training for epoch 196 done, starting evaluation\n",
      "Epoch 196 performance:\n",
      "metrics/test.rmse:  2.110\n",
      "metrics/test.rmse_pcutoff:2.110\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 196/200 (lr=1e-06), train loss 0.00014, valid loss 0.00089\n",
      "Training for epoch 197 done, starting evaluation\n",
      "Epoch 197 performance:\n",
      "metrics/test.rmse:  2.108\n",
      "metrics/test.rmse_pcutoff:2.108\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 197/200 (lr=1e-06), train loss 0.00017, valid loss 0.00088\n",
      "Training for epoch 198 done, starting evaluation\n",
      "Epoch 198 performance:\n",
      "metrics/test.rmse:  2.117\n",
      "metrics/test.rmse_pcutoff:2.117\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 198/200 (lr=1e-06), train loss 0.00015, valid loss 0.00088\n",
      "Training for epoch 199 done, starting evaluation\n",
      "Epoch 199 performance:\n",
      "metrics/test.rmse:  2.128\n",
      "metrics/test.rmse_pcutoff:2.128\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 199/200 (lr=1e-06), train loss 0.00016, valid loss 0.00089\n",
      "Training for epoch 200 done, starting evaluation\n",
      "Epoch 200 performance:\n",
      "metrics/test.rmse:  2.106\n",
      "metrics/test.rmse_pcutoff:2.106\n",
      "metrics/test.mAP:   80.875\n",
      "metrics/test.mAR:   83.333\n",
      "metrics/test.mAP_pcutoff:80.875\n",
      "metrics/test.mAR_pcutoff:83.333\n",
      "Epoch 200/200 (lr=1e-06), train loss 0.00015, valid loss 0.00089\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 114/114 [00:05<00:00, 19.62it/s]\n",
      "100%|| 6/6 [00:00<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200-results.csv (pcutoff: 0.6):\n",
      "train rmse             0.95\n",
      "train rmse_pcutoff     0.95\n",
      "train mAP             94.05\n",
      "train mAR             96.58\n",
      "train mAP_pcutoff     94.05\n",
      "train mAR_pcutoff     96.58\n",
      "test rmse              2.11\n",
      "test rmse_pcutoff      2.11\n",
      "test mAP              80.87\n",
      "test mAR              83.33\n",
      "test mAP_pcutoff      80.87\n",
      "test mAR_pcutoff      83.33\n",
      "Name: (0.95, 1, 200, -1, 0.6), dtype: float64\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\schiv\\\\OneDrive\\\\Desktop\\\\Cours\\\\Master\\\\GSON\\\\Stage_M1\\\\Travail\\\\Scripts\\\\open_field_model\\\\open_field_zone-Me-2024-07-11\\\\evaluation-results-pytorch\\\\iteration-0\\\\open_field_zoneJul11-trainset95shuffle1\\\\DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200-results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mShuffles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplotting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgputouse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\compat.py:471\u001b[0m, in \u001b[0;36mevaluate_network\u001b[1;34m(config, Shuffles, trainingsetindex, plotting, show_errors, comparisonbodyparts, gputouse, rescale, modelprefix, per_keypoint_evaluation, engine, **torch_kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_estimation_pytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_network\n\u001b[0;32m    470\u001b[0m     _update_device(gputouse, torch_kwargs)\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluate_network(\n\u001b[0;32m    472\u001b[0m         config,\n\u001b[0;32m    473\u001b[0m         shuffles\u001b[38;5;241m=\u001b[39mShuffles,\n\u001b[0;32m    474\u001b[0m         trainingsetindex\u001b[38;5;241m=\u001b[39mtrainingsetindex,\n\u001b[0;32m    475\u001b[0m         plotting\u001b[38;5;241m=\u001b[39mplotting,\n\u001b[0;32m    476\u001b[0m         show_errors\u001b[38;5;241m=\u001b[39mshow_errors,\n\u001b[0;32m    477\u001b[0m         modelprefix\u001b[38;5;241m=\u001b[39mmodelprefix,\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtorch_kwargs,\n\u001b[0;32m    479\u001b[0m     )\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function is not implemented for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_pytorch\\apis\\evaluate.py:454\u001b[0m, in \u001b[0;36mevaluate_network\u001b[1;34m(config, shuffles, trainingsetindex, snapshotindex, device, plotting, show_errors, transform, modelprefix, detector_snapshot_index)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m snapshot \u001b[38;5;129;01min\u001b[39;00m snapshots:\n\u001b[0;32m    447\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m get_scorer_name(\n\u001b[0;32m    448\u001b[0m         cfg\u001b[38;5;241m=\u001b[39mcfg,\n\u001b[0;32m    449\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m         modelprefix\u001b[38;5;241m=\u001b[39mmodelprefix,\n\u001b[0;32m    453\u001b[0m     )\n\u001b[1;32m--> 454\u001b[0m     \u001b[43mevaluate_snapshot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43msnapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplotting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_pytorch\\apis\\evaluate.py:284\u001b[0m, in \u001b[0;36mevaluate_snapshot\u001b[1;34m(cfg, loader, snapshot, scorer, transform, plotting, show_errors, detector_snapshot)\u001b[0m\n\u001b[0;32m    282\u001b[0m scores_filepath \u001b[38;5;241m=\u001b[39m output_filename\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m scores_filepath \u001b[38;5;241m=\u001b[39m scores_filepath\u001b[38;5;241m.\u001b[39mwith_stem(scores_filepath\u001b[38;5;241m.\u001b[39mstem \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 284\u001b[0m \u001b[43msave_evaluation_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcutoff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plotting:\n\u001b[0;32m    287\u001b[0m     folder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabeledImages_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscorer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_pytorch\\apis\\evaluate.py:500\u001b[0m, in \u001b[0;36msave_evaluation_results\u001b[1;34m(df_scores, scores_path, print_results, pcutoff)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_scores\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# Save scores file\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m \u001b[43mdf_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Update combined results\u001b[39;00m\n\u001b[0;32m    503\u001b[0m combined_scores_path \u001b[38;5;241m=\u001b[39m scores_path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombinedEvaluation-results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\schiv\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\schiv\\\\OneDrive\\\\Desktop\\\\Cours\\\\Master\\\\GSON\\\\Stage_M1\\\\Travail\\\\Scripts\\\\open_field_model\\\\open_field_zone-Me-2024-07-11\\\\evaluation-results-pytorch\\\\iteration-0\\\\open_field_zoneJul11-trainset95shuffle1\\\\DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200-results.csv'"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path, Shuffles=[1], plotting=True, gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['open_field_model/open_field_zone-Me-2024-07-11/videos\\\\Test 7.mp4', 'open_field_model/open_field_zone-Me-2024-07-11/videos\\\\Test 8.mp4', 'open_field_model/open_field_zone-Me-2024-07-11/videos\\\\Test 9.mp4']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "videos = glob.glob(\"open_field_model/open_field_zone-Me-2024-07-11/videos\"+\"/Test [7-9].mp4\")\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing videos with C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\dlc-models-pytorch\\iteration-0\\open_field_zoneJul11-trainset95shuffle1\\train\\snapshot-200.pt\n",
      "Starting to analyze open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 7.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    31088\n",
      "  Duration of video [s]:  1800.12\n",
      "  fps:                    17.27\n",
      "  resolution:             w=640, h=480\n",
      "\n",
      "Running Pose Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31088/31088 [23:45<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 7DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200.h5 and open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 7DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "Analyzing videos with C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\dlc-models-pytorch\\iteration-0\\open_field_zoneJul11-trainset95shuffle1\\train\\snapshot-200.pt\n",
      "Starting to analyze open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 8.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    31095\n",
      "  Duration of video [s]:  1800.52\n",
      "  fps:                    17.27\n",
      "  resolution:             w=640, h=480\n",
      "\n",
      "Running Pose Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31095/31095 [23:53<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 8DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200.h5 and open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 8DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "Analyzing videos with C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\dlc-models-pytorch\\iteration-0\\open_field_zoneJul11-trainset95shuffle1\\train\\snapshot-200.pt\n",
      "Starting to analyze open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 9.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    31082\n",
      "  Duration of video [s]:  1799.77\n",
      "  fps:                    17.27\n",
      "  resolution:             w=640, h=480\n",
      "\n",
      "Running Pose Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31082/31082 [24:07<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 9DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200.h5 and open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 9DLC_HrnetW48_open_field_zoneJul11shuffle1_snapshot_200_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v in videos:\n",
    "    deeplabcut.analyze_videos(config_path, v, save_as_csv=True, gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 20.mp4\n",
      "Loading C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 20.mp4 and data.\n",
      "Labeled video already created. Skipping...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path, [r'C:\\Users\\schiv\\OneDrive\\Desktop\\Cours\\Master\\GSON\\Stage_M1\\Travail\\Scripts\\open_field_model\\open_field_zone-Me-2024-07-11\\videos\\Test 20.mp4'], save_frames = True, videotype='mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.zeros(1).cuda())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
